{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "585fac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66171990",
   "metadata": {},
   "source": [
    "### 1. Metrics(Accuracy, Precision, Recall, F1_score, AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "88119f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    \n",
    "    print('Confusion Matrix')\n",
    "    print(confusion)\n",
    "    print('Accuracy: {0:.4f}, Precision: {1:.4f}, Recall: {2:.4f}, F1: {3:.4f}, AUC: {4:.4f}'\n",
    "          .format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d00a89",
   "metadata": {},
   "source": [
    "### 2. Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "056c1aee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape:(10276, 206)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset_name = \"feature_permission.csv\"\n",
    "dataset = pd.read_csv(dataset_name)\n",
    "X_features = dataset.loc[:,dataset.columns != 'label']\n",
    "\n",
    "y_label = dataset['label']\n",
    "\n",
    "dataset.loc[:,dataset.columns != 'label']\n",
    "print('Feature shape:{0}'.format(X_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9caaa71",
   "metadata": {},
   "source": [
    "### 3. Dataset Split(Train, Eval, Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "62e0a854",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape:(6165, 206), Eval Shape:(2055, 206) Test Shape:(2056, 206)\n",
      "\n",
      "Train\n",
      "1.0    5448\n",
      "0.0     717\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Eval\n",
      "1.0    1819\n",
      "0.0     236\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Test\n",
      "1.0    1830\n",
      "0.0     226\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# with validation date\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_label,\n",
    "                                                    test_size=0.4, random_state=0)\n",
    "X_eval, X_test, y_eval, y_test = train_test_split(X_test, y_test, \n",
    "                                                  test_size=0.5, random_state=0)\n",
    "\n",
    "train_cnt = y_train.count() # train 데이터 수\n",
    "eval_cnt = y_eval.count() # validation 데이터 수\n",
    "test_cnt = y_test.count() # test 데이터 수\n",
    "\n",
    "\n",
    "print('Train Shape:{0}, Eval Shape:{1} Test Shape:{2}'.format(X_train.shape, X_eval.shape, X_test.shape))\n",
    "\n",
    "print('\\nTrain')\n",
    "# print(y_train.value_counts()/train_cnt)\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print('\\nEval')\n",
    "# print(y_eval.value_counts()/eval_cnt)\n",
    "print(y_eval.value_counts())\n",
    "\n",
    "print('\\nTest')\n",
    "# print(y_test.value_counts()/test_cnt)\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fba487",
   "metadata": {},
   "source": [
    "### 4. Train with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a1833b",
   "metadata": {},
   "source": [
    "HyperParamter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f14b8131",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# grid_param ={'max_depth' : [3, 5, 7, 9, 11],\n",
    "#              'n_estimators': [600, 700,800,900,1000],\n",
    "#              'learning_rate': [0.01,0.05, 0.1, 0.15, 0.2],\n",
    "#              'objective':['binary:logistic'],\n",
    "#              'eval_metric': ['logloss'],\n",
    "#              'gamma': [0, 0.5, 1, 2],\n",
    "#              'random_state':[51],\n",
    "#             }\n",
    "\n",
    "grid_param ={'max_depth' : [3],\n",
    "             'n_estimators': [600,1000],\n",
    "             'learning_rate': [0.01],\n",
    "             'objective':['binary:logistic'],\n",
    "             'eval_metric': ['logloss'],\n",
    "             'gamma': [0],\n",
    "             'random_state':[51],\n",
    "            }\n",
    "xgb_clf = XGBClassifier(early_stopping_rounds=50)\n",
    "evals = [(X_eval, y_eval)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da97d68a",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04ad1522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total learning time:  59.33447575569153\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#verbose: 학습 과정 출력\n",
    "grid_xgb_clf = GridSearchCV(xgb_clf, param_grid = grid_param, cv = 5, refit = True, verbose = 0)\n",
    "grid_xgb_clf.fit(X_train, y_train, eval_set = evals, verbose = False)\n",
    "\n",
    "print(\"Total learning time: \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8ac7cd",
   "metadata": {},
   "source": [
    "### 5. Best parameter and estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c183d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(grid_xgb_clf)\n",
    "# 최적의 하이퍼 파라미터 출력\n",
    "best_params=grid_xgb_clf.best_params_\n",
    "\n",
    "# 최적의 하이퍼 파라미터로 학습된 모델 best_estimator에 저장\n",
    "best_estimator = grid_xgb_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ae6338a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_metric': 'logloss', 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 1000, 'objective': 'binary:logistic', 'random_state': 51}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "66eafa55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "[0.99840754 0.9978066  0.99516356 ... 0.9989027  0.9989027  0.99809164]\n"
     ]
    }
   ],
   "source": [
    "w_preds = grid_xgb_clf.predict(X_test) # 분류 결과(label)\n",
    "print(w_preds)\n",
    "\n",
    "w_pred_proba = grid_xgb_clf.predict_proba(X_test)[:,1] # 분류 결과(확률)\n",
    "print(w_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1d6c62d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 179   47]\n",
      " [  28 1802]]\n",
      "Accuracy: 0.9635, Precision: 0.9746, Recall: 0.9847, F1: 0.9796, AUC: 0.9838\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_test, w_preds, w_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9724d5",
   "metadata": {},
   "source": [
    "### 6. Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d8d1cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 파일로 저장, 저장형식은 json, 하지만 json은 txt로 저장했을 때 보다 용량이 2배크다...\n",
    "best_estimator.save_model('Binary_grid_xgb.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a9f52b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd90e44",
   "metadata": {},
   "source": [
    "## Model Load\n",
    "저장된 모델 재사용 하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c0d7558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7d5e173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    \n",
    "    print('Confusion Matrix')\n",
    "    print(confusion)\n",
    "    print('Accuracy: {0:.4f}, Precision: {1:.4f}, Recall: {2:.4f}, F1: {3:.4f}, AUC: {4:.4f}'\n",
    "          .format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643689e4",
   "metadata": {},
   "source": [
    "### 1. Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6aa38c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape:(10276, 206)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"feature_permission.csv\")\n",
    "X_features = dataset.loc[:,dataset.columns != 'label']\n",
    "\n",
    "y_label = dataset['label']\n",
    "\n",
    "dataset.loc[:,dataset.columns != 'label']\n",
    "print('Feature shape:{0}'.format(X_features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8a09cf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape:(6165, 206), Eval Shape:(2055, 206) Test Shape:(2056, 206)\n",
      "\n",
      "Train\n",
      "1.0    5448\n",
      "0.0     717\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Eval\n",
      "1.0    1819\n",
      "0.0     236\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Test\n",
      "1.0    1830\n",
      "0.0     226\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# with validation date\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_label,\n",
    "                                                    test_size=0.4, random_state=0)\n",
    "X_eval, X_test, y_eval, y_test = train_test_split(X_test, y_test, \n",
    "                                                  test_size=0.5, random_state=0)\n",
    "\n",
    "train_cnt = y_train.count() # train 데이터 수\n",
    "eval_cnt = y_eval.count() # validation 데이터 수\n",
    "test_cnt = y_test.count() # test 데이터 수\n",
    "\n",
    "\n",
    "print('Train Shape:{0}, Eval Shape:{1} Test Shape:{2}'.format(X_train.shape, X_eval.shape, X_test.shape))\n",
    "\n",
    "print('\\nTrain')\n",
    "# print(y_train.value_counts()/train_cnt)\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print('\\nEval')\n",
    "# print(y_eval.value_counts()/eval_cnt)\n",
    "print(y_eval.value_counts())\n",
    "\n",
    "print('\\nTest')\n",
    "# print(y_test.value_counts()/test_cnt)\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71be464e",
   "metadata": {},
   "source": [
    "### 2. Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "455741b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = XGBClassifier()\n",
    "load_model.load_model('Binary_grid_xgb.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f048975",
   "metadata": {},
   "source": [
    "### 3. Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8a4d3bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "[0.99840754 0.9978066  0.99516356 ... 0.9989027  0.9989027  0.99809164]\n"
     ]
    }
   ],
   "source": [
    "w_preds = load_model.predict(X_test) # 분류 결과(label)\n",
    "print(w_preds)\n",
    "\n",
    "w_pred_proba = load_model.predict_proba(X_test)[:,1] # 분류 결과(확률)\n",
    "print(w_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1a2d8980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 179   47]\n",
      " [  28 1802]]\n",
      "Accuracy: 0.9635, Precision: 0.9746, Recall: 0.9847, F1: 0.9796, AUC: 0.9838\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_test, w_preds, w_pred_proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
